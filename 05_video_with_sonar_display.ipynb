{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02cca469",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x9/scyyg02s20v0759sw_qxdlqc0000gn/T/ipykernel_66068/1544386504.py:122: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  cmap = cm.get_cmap(cmap_name).copy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 592 frames to exports/videos/20240822_140646_088691+0200_sonar_video.mp4 @ 15.67 FPS\n"
     ]
    }
   ],
   "source": [
    "# === Sonar + Camera Side-by-Side VIDEO (with optional vertical cone flip) ===\n",
    "import os, re, json\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "try:\n",
    "    from zoneinfo import ZoneInfo\n",
    "except Exception:\n",
    "    ZoneInfo = None\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "# Import functions from utils instead of redefining them\n",
    "from utils.sonar_utils import (\n",
    "    load_df, parse_json_cell, infer_hw, get_sonoptix_frame, \n",
    "    enhance_intensity, read_video_index, apply_flips, cone_raster_like_display_cell\n",
    ")\n",
    "\n",
    "# ---------- CONFIG (edit these) ----------\n",
    "SONAR_FILE     = Path(\"exports/by_bag/sensor_sonoptix_echo_image__2024-08-22_14-06-43_video.csv\")\n",
    "VIDEO_SEQ_DIR  = Path(\"exports/frames/2024-08-22_14-06-43_video__image_compressed_image_data\")\n",
    "OUT_DIR        = Path(\"exports/videos\")\n",
    "\n",
    "# Selection / speed\n",
    "START_IDX      = 0\n",
    "END_IDX        = None\n",
    "STRIDE         = 1\n",
    "TARGET_FPS     = None\n",
    "\n",
    "# Timestamp matching\n",
    "TIME_TOLERANCE = pd.Timedelta(\"100ms\")\n",
    "\n",
    "# Sonar geometry / display (must match your static cone cell)\n",
    "FOV_DEG              = 120.0\n",
    "RANGE_MIN_M          = 0.0\n",
    "RANGE_MAX_M          = 30.0\n",
    "DISPLAY_RANGE_MAX_M  = 10.0\n",
    "FLIP_BEAMS           = True\n",
    "FLIP_RANGE           = False\n",
    "\n",
    "# Enhancement (display only)\n",
    "USE_ENHANCED         = True\n",
    "ENH_SCALE            = \"db\"          # \"db\" | \"linear\"\n",
    "ENH_TVG              = \"amplitude\"   # \"none\" | \"amplitude\" | \"power\"\n",
    "ENH_ALPHA_DB_PER_M   = 0.0\n",
    "ENH_R0               = 1e-2\n",
    "ENH_P_LOW            = 1.0\n",
    "ENH_P_HIGH           = 99.5\n",
    "ENH_GAMMA            = 0.9\n",
    "ENH_ZERO_AWARE       = True\n",
    "ENH_EPS_LOG          = 1e-6\n",
    "\n",
    "# Visuals / sizes\n",
    "CMAP_RAW     = \"viridis\"\n",
    "CMAP_ENH     = \"viridis\"\n",
    "CONE_W, CONE_H = 900, 700\n",
    "VIDEO_HEIGHT   = CONE_H\n",
    "PAD_BETWEEN    = 8\n",
    "FONT_SCALE     = 0.55\n",
    "\n",
    "# <<< NEW: flip cone vertically (top↔bottom). True puts apex at the bottom. >>>\n",
    "CONE_FLIP_VERTICAL = True\n",
    "# ----------------------------------------\n",
    "\n",
    "# ---------- unique helper functions ----------\n",
    "def load_png_bgr(path: Path) -> np.ndarray:\n",
    "    img = cv2.imread(str(path), cv2.IMREAD_COLOR)\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(path)\n",
    "    return img\n",
    "\n",
    "def to_local(ts, tz_name=\"Europe/Oslo\"):\n",
    "    try: return ts.tz_convert(tz_name)\n",
    "    except Exception: return ts\n",
    "\n",
    "def ts_for_name(ts, tz_name=\"Europe/Oslo\"):\n",
    "    if pd.isna(ts): ts = pd.Timestamp.utcnow().tz_localize(\"UTC\")\n",
    "    return to_local(ts, tz_name).strftime(\"%Y%m%d_%H%M%S_%f%z\")\n",
    "\n",
    "def put_text(bgr, s, y, x=10, scale=FONT_SCALE):\n",
    "    cv2.putText(bgr, s, (x, y), cv2.FONT_HERSHEY_SIMPLEX, scale, (255,255,255), 2, cv2.LINE_AA)\n",
    "    cv2.putText(bgr, s, (x, y), cv2.FONT_HERSHEY_SIMPLEX, scale, (0,0,0),   1, cv2.LINE_AA)\n",
    "\n",
    "# ---------- load sonar ----------\n",
    "df = load_df(SONAR_FILE)\n",
    "if \"ts_utc\" not in df.columns:\n",
    "    if \"t\" not in df.columns:\n",
    "        raise RuntimeError(\"Sonar CSV missing 't' column for timestamps.\")\n",
    "    df[\"ts_utc\"] = pd.to_datetime(df[\"t\"], unit=\"s\", utc=True, errors=\"coerce\")\n",
    "\n",
    "N = len(df)\n",
    "i0 = int(max(0, START_IDX))\n",
    "i1 = int(N if END_IDX is None else min(N, END_IDX))\n",
    "idxs = list(range(i0, i1, max(1, STRIDE)))\n",
    "if not idxs:\n",
    "    raise RuntimeError(\"No frames selected; adjust START/END/STRIDE.\")\n",
    "\n",
    "# FPS from sonar timestamps if not forced\n",
    "if TARGET_FPS is None:\n",
    "    ts = pd.to_datetime(df.loc[idxs, \"ts_utc\"], utc=True, errors=\"coerce\").dropna().sort_values().reset_index(drop=True)\n",
    "    dt_s = ts.diff().dt.total_seconds().to_numpy()[1:]\n",
    "    dt_s = dt_s[(dt_s > 1e-6) & (dt_s < 5.0)]\n",
    "    fps = float(np.clip(1.0/np.median(dt_s), 1.0, 60.0)) if dt_s.size else 12.0\n",
    "else:\n",
    "    fps = float(TARGET_FPS)\n",
    "\n",
    "# ---------- video index & writer ----------\n",
    "dfv = read_video_index(VIDEO_SEQ_DIR)\n",
    "dfv = dfv.dropna(subset=[\"ts_utc\"]).sort_values(\"ts_utc\").reset_index(drop=True)\n",
    "video_idx = pd.Index(dfv[\"ts_utc\"])\n",
    "\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "first_ts = pd.to_datetime(df.loc[idxs[0], \"ts_utc\"], utc=True, errors=\"coerce\")\n",
    "out_name = ts_for_name(first_ts, \"Europe/Oslo\") + \"_sonar_video.mp4\"\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "writer = None\n",
    "\n",
    "# colormap (NaN -> black)\n",
    "cmap_name = (CMAP_ENH if USE_ENHANCED else CMAP_RAW)\n",
    "cmap = cm.get_cmap(cmap_name).copy()\n",
    "cmap.set_bad((0,0,0,1))\n",
    "\n",
    "frames_written = 0\n",
    "half = np.deg2rad(0.5 * FOV_DEG)\n",
    "x_max_m = np.sin(half) * DISPLAY_RANGE_MAX_M\n",
    "\n",
    "def x_px(xm):\n",
    "    return int(round((xm + x_max_m) / (2*x_max_m) * (CONE_W-1)))\n",
    "\n",
    "def y_px_nominal(ym):\n",
    "    # nominal: y=0 at top (OpenCV row 0), y=y_max at bottom\n",
    "    return int(round((ym - 0.0) / (DISPLAY_RANGE_MAX_M - 0.0 + 1e-12) * (CONE_H-1)))\n",
    "\n",
    "def y_px(ym):\n",
    "    yp = y_px_nominal(ym)\n",
    "    # <<< NEW: invert for vertical flip so apex (0 m) goes to the bottom >>>\n",
    "    if CONE_FLIP_VERTICAL:\n",
    "        yp = (CONE_H - 1) - yp\n",
    "    return yp\n",
    "\n",
    "for k, i in enumerate(idxs):\n",
    "    # ---- SONAR frame matrix ----\n",
    "    M0 = get_sonoptix_frame(df, i)\n",
    "    if M0 is None:\n",
    "        continue\n",
    "    \n",
    "    # Apply flips using utility function\n",
    "    M = apply_flips(M0, flip_range=FLIP_RANGE, flip_beams=FLIP_BEAMS)\n",
    "    H, W = M.shape\n",
    "\n",
    "    Z = enhance_intensity(M, RANGE_MIN_M, RANGE_MAX_M,\n",
    "                         scale=ENH_SCALE, tvg=ENH_TVG, alpha_db_per_m=ENH_ALPHA_DB_PER_M,\n",
    "                         r0=ENH_R0, p_low=ENH_P_LOW, p_high=ENH_P_HIGH,\n",
    "                         gamma=ENH_GAMMA, zero_aware=ENH_ZERO_AWARE, eps_log=ENH_EPS_LOG) if USE_ENHANCED else M\n",
    "\n",
    "    # Use utility function for cone rasterization\n",
    "    cone, (x_min, x_max, y_min, y_max) = cone_raster_like_display_cell(\n",
    "        Z, FOV_DEG, RANGE_MIN_M, RANGE_MAX_M, DISPLAY_RANGE_MAX_M, CONE_W, CONE_H\n",
    "    )\n",
    "\n",
    "    # colorize cone → BGR\n",
    "    cone_rgb = (cmap(np.ma.masked_invalid(cone))[:, :, :3] * 255).astype(np.uint8)\n",
    "    cone_bgr = cv2.cvtColor(cone_rgb, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # <<< NEW: flip vertically if requested >>>\n",
    "    if CONE_FLIP_VERTICAL:\n",
    "        cone_bgr = cv2.flip(cone_bgr, 0)\n",
    "\n",
    "    # ---- CAMERA: nearest by timestamp ----\n",
    "    ts_target = pd.to_datetime(df.loc[i, \"ts_utc\"], utc=True, errors=\"coerce\")\n",
    "    idx_near = video_idx.get_indexer([ts_target], method=\"nearest\")[0]\n",
    "    ts_cam = dfv.loc[idx_near, \"ts_utc\"]\n",
    "    dt = abs(ts_cam - ts_target)\n",
    "    if dt > TIME_TOLERANCE and (k % 100 == 0):\n",
    "        print(f\"(warn) |Δt|={dt} > {TIME_TOLERANCE} at sonar idx {i}; using nearest frame.\")\n",
    "    cam_file = VIDEO_SEQ_DIR / dfv.loc[idx_near, \"file\"]\n",
    "    cam_bgr = load_png_bgr(cam_file)\n",
    "\n",
    "    # scale camera to VIDEO_HEIGHT\n",
    "    vh, vw0 = cam_bgr.shape[:2]\n",
    "    scale = VIDEO_HEIGHT / vh\n",
    "    cam_resized = cv2.resize(cam_bgr, (int(round(vw0*scale)), VIDEO_HEIGHT), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # composite canvas (cam | pad | cone)\n",
    "    pad = np.zeros((CONE_H, PAD_BETWEEN, 3), dtype=np.uint8)\n",
    "    composite = np.hstack([cam_resized, pad, cone_bgr])\n",
    "\n",
    "    # init writer once\n",
    "    if writer is None:\n",
    "        out_size = (composite.shape[1], composite.shape[0])\n",
    "        writer = cv2.VideoWriter(str(OUT_DIR / out_name), fourcc, fps, out_size, True)\n",
    "        if not writer.isOpened():\n",
    "            raise RuntimeError(f\"Could not open writer: {OUT_DIR/out_name}\")\n",
    "\n",
    "    # overlays: timestamps & settings\n",
    "    ts_cam_loc   = to_local(ts_cam,   \"Europe/Oslo\")\n",
    "    ts_sonar_loc = to_local(ts_target,\"Europe/Oslo\")\n",
    "    put_text(composite, f\"VIDEO  @ {ts_cam_loc:%Y-%m-%d %H:%M:%S.%f %Z}\", 24)\n",
    "    put_text(composite, f\"SONAR  @ {ts_sonar_loc:%Y-%m-%d %H:%M:%S.%f %Z}   Δt={dt.total_seconds():.3f}s\", 48)\n",
    "    put_text(composite, f\"FOV={FOV_DEG:.0f}°, range={RANGE_MIN_M:.0f}-{DISPLAY_RANGE_MAX_M:.0f} m  ({'enhanced' if USE_ENHANCED else 'raw'})\", 72)\n",
    "\n",
    "    # spokes (no arcs), with vertical flip-aware Y mapping\n",
    "    x_off = cam_resized.shape[1] + PAD_BETWEEN\n",
    "    N_SPOKES = 5\n",
    "    for a in np.linspace(-np.rad2deg(half), np.rad2deg(half), N_SPOKES):\n",
    "        th = np.deg2rad(a)\n",
    "        x_end = x_px(DISPLAY_RANGE_MAX_M * np.sin(th))\n",
    "        y_end = y_px(DISPLAY_RANGE_MAX_M * np.cos(th))\n",
    "        apex_x = x_off + x_px(0.0)\n",
    "        apex_y = y_px(0.0)\n",
    "        cv2.line(composite, (apex_x, apex_y), (x_off + x_end, y_end), (0,0,0), 2, cv2.LINE_AA)\n",
    "        cv2.line(composite, (apex_x, apex_y), (x_off + x_end, y_end), (255,255,255), 1, cv2.LINE_AA)\n",
    "\n",
    "    writer.write(composite)\n",
    "    frames_written += 1\n",
    "\n",
    "if writer is not None:\n",
    "    writer.release()\n",
    "print(f\"Wrote {frames_written} frames to {OUT_DIR/out_name} @ {fps:.2f} FPS\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
